auction_list<-data.frame(rbind(SubcatDataAuc %>% select(Schedule),auction_categ %>% select(Schedule)) %>% distinct())
### Number of category
nCat_auc<-dim(auction_list)[1]
SF_A<-matrix(0,nCat_auc)
### Run model, loop through schedules
for (j in 1:nCat_auc){
groupData_A<-subset(ModelData_Auction,ModelData_Auction$Schedule==auction_list[j,1])
groupDataft <- groupData_A %>%
filter(Y <= quantile(Y,0.75) + 2*IQR(Y) & Y>= quantile(Y,0.25) - 2*IQR(Y))
fitData<-within(groupDataft,CountryCode<-relevel(CountryCode,ref="USA"))
fitG<-lm(log(Y)~CountryCode,data=fitData)
SF_A[j]<-exp(fitG$coefficients[2])
}
### output results
rownames(SF_A)<-auction_list[,1]
SF_A<-rownames_to_column(data.frame(SF_A))
colnames(SF_A)<-c("Schedule","Auction")
###############################################################################################################################
##################################################### Scale Factor Calculation ################################################
###############################################################################################################################
### pull the number of sales in each category in CAN
summaryAuc<-ModelData_Auction %>%
filter(CountryCode=='CAN') %>%
group_by(Schedule) %>%
summarise(nAuc=n())
summaryRet<-ModelData_Retail %>%
filter(CountryCode=='CAN') %>%
group_by(Schedule) %>%
summarise(nRet=n())
### merge retail and auction
Mergecounts<-merge(data.frame(summaryRet),data.frame(summaryAuc),by=c("Schedule"),all = T)
MergeAdj<-merge(SF_R,SF_A,by=c("Schedule"),all = T)
CalcAdj<-merge(MergeAdj,Mergecounts,by=c("Schedule"))
### calculate the global values #######################
Global <- CalcAdj %>%
drop_na() %>%
summarise(RetGlob = crossprod(Retail,nRet)/sum(nRet),
AucGlob = crossprod(Auction,nAuc)/sum(nAuc),
CountGlobRet = sum(nRet),
CountGlobAuc = sum(nAuc))
Global<-rownames_to_column(data.frame(Global))
Global$rowname = global
colnames(Global) <- c("Schedule","Retail","Auction", "nRet", "nAuc")
### Scale factors by schedules before any adjustments
AdjusterTB<-data.frame(as.list(rbind(Global,CalcAdj)))
#write.csv(AdjusterTB,"CANSF_Subcat0228.csv")
# assign values for borrowing schedules
join_brwIn<-merge(AdjusterTB %>% select(-nRet,-nAuc),inputBorw %>% select(Schedule,BorrowSchedule) %>% distinct(), by=c('Schedule'),all.x=T)
adj_output<-merge(join_brwIn,AdjusterTB %>% select(-nRet,-nAuc), by.y='Schedule',by.x='BorrowSchedule',all.x=T) %>%
mutate(Retail = ifelse(is.na(Retail.x), Retail.y, Retail.x),
Auction = ifelse(is.na(Auction.x), Auction.y, Auction.x)) %>%
select(Schedule, Retail, Auction)
#############################################################################################################################
##################################################### Cap, Channel, MoMLimit ################################################
#############################################################################################################################
#### prepare the table with caps
globcaps<-data.frame(global,Min_delta,lowerB,upperB)
names(globcaps)<-names(caps_table0)
caps_table <- rbind(caps_table0,globcaps)
join_cap <- merge(adj_output,caps_table,by='Schedule',all.x=T)
### CAP the adjusters to lower and upper bounds
Cap_Canada<-join_cap %>%
mutate(cap_retail = pmin(as.numeric(CapsMax),pmax(Retail,as.numeric(CapsMin))),
cap_auction = pmin(as.numeric(CapsMax),pmax(Auction,as.numeric(CapsMin))))
### Apply minimum delta for channel
MinDelta<-Cap_Canada %>%
mutate(delta_ret = cap_retail -1, delta_auc = cap_auction -1) %>%
mutate(move_ret = minimumDelta(delta_auc,delta_ret,delta_ret,as.numeric(Delta)),
move_auc = minimumDelta(delta_auc,delta_ret,delta_auc,as.numeric(Delta))) %>%
mutate(chancheck_ret = cap_retail - move_ret,
chancheck_auc = cap_auction - move_auc) %>%
select(-delta_ret, -delta_auc,  -move_ret,-move_auc)
""""""
#MinDelta<-Cap_Canada %>%
#  mutate(chancheck_ret = ifelse(cap_auction-cap_retail > as.numeric(Delta), cap_auction-as.numeric(Delta), cap_retail),
#         chancheck_auc = cap_auction)
### Join to the application file
mergeAppl<-merge(comb_apply,MinDelta,by=c("Schedule"),all.x=TRUE) %>%
replace(.=='NULL','') %>%
mutate(CodeCS = paste(CategoryId,SubcategoryId,sep = '|')) %>%
select(Schedule,CodeCS,CategoryId,SubcategoryId,CategoryName,SubcategoryName,Retail,Auction,cap_retail, cap_auction, chancheck_ret, chancheck_auc)
### global
Globalrow<-MinDelta %>%
filter(Schedule==global) %>%
mutate(CodeCS = paste(globalId,'|'),Schedule=paste('.',global),CategoryId=globalId,SubcategoryId='',CategoryName=global,SubcategoryName='') %>%
select(Schedule,CodeCS,CategoryId,SubcategoryId,CategoryName,SubcategoryName,Retail,Auction,cap_retail, cap_auction, chancheck_ret, chancheck_auc)
### append global with others
combApplication = rbind(Globalrow,mergeAppl)
### MoM limit
lastM_cap<-merge(combApplication,LastMonthconcat,by=c('CodeCS'),all.x=T) %>%
mutate(retail_final = MoMlimit(RetailPercent,chancheck_ret,LstM_limit),
auction_final =  MoMlimit(AuctionPercent,chancheck_auc,LstM_limit))
#############################################################################################################################
##################################################### Final files and export ################################################
#############################################################################################################################
### Upload file
ExportTb <-lastM_cap %>%
rename(retail=retail_final,auction=auction_final) %>%
select(CategoryId,SubcategoryId,retail,auction) %>%
mutate(CountryAdjusterTypeID=1)
ExportTb[is.na(ExportTb)]<-''
### Share page
sharepage<-lastM_cap %>%
mutate(retailDiff = retail_final-RetailPercent,
auctionDiff = auction_final-AuctionPercent) %>%
select(Schedule,CategoryName,SubcategoryName, RetailPercent, AuctionPercent, retail_final, auction_final,
retailDiff,  auctionDiff, chancheck_ret ,chancheck_auc,cap_retail , cap_auction,Retail,Auction) %>%
arrange(Schedule,CategoryName,SubcategoryName)
sharepage2<-rbind(merge(month_thres.Retail.trans,'Retail'),merge(month_thres.Auction.trans,'Auction')) %>%
mutate(OldestMonthInuse = if_else(as.Date(Monthback) >=thresholdMonth,thresholdMonth,as.Date(Monthback)))%>%
select(Schedule,y,OldestMonthInuse) %>%
rename(SaleType=y)
### Export the files
write.csv(ExportTb,uploadFile,row.names = F)
write.xlsx2(as.data.frame(sharepage),file = paste(Sys.Date(),'MoMSharePage_Canada.xlsx'), sheetName = 'SharePage1',row.names = F)
write.xlsx2(as.data.frame(sharepage2),file = paste(Sys.Date(),'MoMSharePage_Canada.xlsx'), sheetName = 'SharePage2',append=T,row.names = F)
#1) Run Schedule
#2) Run Canada
#3)
library(RODBC)
library(lattice)
library(latticeExtra)
library(dplyr)
library(xlsx)
library(lubridate)
library(stringr)
library(glue)
CanadaExlfile='20200727 CanadaManagement.xlsx'
mngfile_us = '20200717 SchedulesManagement.xlsx'
channel<-odbcConnect("production")
file_path<-"C:/Users/vanessa.li/Documents/GitHub/Canadian-Adjustments"
setwd(file_path)
plotFolder = paste("Plots",Sys.Date())
dir.create(plotFolder)
#read_dataload<-parse('dataread_CAN.r')
#eval(read_dataload)
publishDate <- Sys.Date() - days(day(Sys.Date()))
thirdLastM<-as.Date(publishDate%m-% months(1)- days(day(publishDate)))
starttime_dtload<-Sys.time()
#Canada inprogress schedule (current month)
CanSchedLoad<-sqlQuery(channel,inprog_sched)
CanSchedprior<-sqlQuery(channel,prior_sched)
### Retail
DataRet<-sqlQuery(channel,salesdt_ret)
### Auction
DataAuc<-sqlQuery(channel,salesdt_auc)
end_time_dtload <- Sys.time()
end_time_dtload - starttime_dtload
## read input files
In<-data.frame(read.xlsx(mngfile_us,sheetName='In')) %>% select(Schedule, Level2, CategoryId, SubcategoryId, CanadaPlots)
In_plots<-In %>% filter(CanadaPlots=='Y')
inputFeed <-rbind(read.xlsx(CanadaExlfile,sheetName='In') %>% select(Schedule,Level2,CategoryId, SubcategoryId),
read.xlsx(CanadaExlfile,sheetName='InR') %>% select(Schedule,Level2,CategoryId, SubcategoryId)) %>%
filter(!str_detect(Schedule,'For Caps')) %>%
rename(Sched.can = Schedule)
## map the US sched mgmt file to Canada file to get USsched.name - CanadaAdj.name
Catlevel<-merge(subset(In_plots,In_plots$Level2 =='Category') %>% select(Schedule,CategoryId),
subset(inputFeed,inputFeed$Level2 =='Category') %>% select(Sched.can,CategoryId),by='CategoryId',all.x=T)
Subcatlevel<-merge(subset(In_plots,In_plots$Level2 =='SubcatGroup') %>% select(Schedule,CategoryId,SubcategoryId),
subset(inputFeed,inputFeed$Level2 =='SubCategory') %>% select(Sched.can,CategoryId,SubcategoryId),by=c('CategoryId','SubcategoryId'),all.x=T)
## assign in progress Canada schedule with schedule name
CatSched<-CanSchedLoad %>% filter(is.na(SubcategoryId))
SubcatSched<-CanSchedLoad %>% filter(!is.na(SubcategoryId))
CatschedJoin <- merge(CatSched,Catlevel, by=c("CategoryId")) %>% select(Schedule,Sched.can,ModelYear,fmv_usa,flv_usa,fmv_can,flv_can)
SubcatschedJoin<-merge(SubcatSched,Subcatlevel, by=c("CategoryId","SubcategoryId")) %>% select(Schedule,Sched.can,ModelYear,fmv_usa,flv_usa,fmv_can,flv_can) %>% distinct()
inprogScheds<- rbind(CatschedJoin,SubcatschedJoin) %>% arrange(Schedule,desc(ModelYear)) %>%
mutate(Age= year(publishDate)-ModelYear + (month(publishDate)-6)/12.00)
## assign prior Canada schedule with schedule name
CatSched.prior<-CanSchedprior %>% filter(is.na(SubcategoryId))
SubcatSched.prior<-CanSchedprior %>% filter(!is.na(SubcategoryId))
CatschedJoin.prior <- merge(CatSched.prior,Catlevel, by=c("CategoryId")) %>% select(Schedule,Sched.can,ModelYear,priorflv,priorfmv)
SubcatschedJoin.prior<-merge(SubcatSched.prior,Subcatlevel, by=c("CategoryId","SubcategoryId")) %>% select(Schedule,Sched.can,ModelYear,priorflv,priorfmv) %>% distinct()
priormonth = as.Date(publishDate- days(day(publishDate)))
priorScheds<- rbind(CatschedJoin.prior,SubcatschedJoin.prior) %>% arrange(Schedule,desc(ModelYear)) %>%
mutate(Age= year(priormonth)-ModelYear + (month(priormonth)-6)/12.00)
# data validation
valid.subcat <- Subcatlevel %>% select(Schedule,Sched.can) %>% distinct()
if(dim(Catlevel)[1]*10 == dim(CatschedJoin)[1] & dim(valid.subcat)[1]*10 == dim(SubcatschedJoin)[1]){
t = dim(Catlevel)[1]+dim(valid.subcat)[1]
message(sprintf("We have %s Canada schedules to print.",t))
plots_schedlist<- rbind(Catlevel %>% select(Schedule,Sched.can),valid.subcat %>% select(Schedule,Sched.can))
} else{message("The numbers of schedules to print is not correct")}
## join sales data to get schedule name
# join to retail data import
CatDataRet <- merge(DataRet %>% filter(CountryCode=='CAN'),Catlevel, by=c("CategoryId")) %>% select(Schedule,Sched.can,SaleAB,Age,EffectiveDate,ModelYear)
SubcatDataRet<-merge(DataRet %>% filter(CountryCode=='CAN'),Subcatlevel, by=c("CategoryId","SubcategoryId")) %>% select(Schedule,Sched.can,SaleAB,Age,EffectiveDate,ModelYear)
Retail_Dt<-rbind(CatDataRet,SubcatDataRet)
recentSales_ret<-Retail_Dt %>% filter(as.Date(EffectiveDate)>=thirdLastM)
olderSales_ret<-Retail_Dt %>% filter(as.Date(EffectiveDate)<thirdLastM)
# join to auction data import
CatDataAuc <- merge(DataAuc %>% filter(CountryCode=='CAN'),Catlevel, by=c("CategoryId")) %>% select(Schedule,Sched.can,SaleAB,Age,EffectiveDate,ModelYear)
SubcatDataAuc<-merge(DataAuc %>% filter(CountryCode=='CAN'),Subcatlevel, by=c("CategoryId","SubcategoryId")) %>% select(Schedule,Sched.can,SaleAB,Age,EffectiveDate,ModelYear)
Auction_Dt<-rbind(CatDataAuc,SubcatDataAuc)
recentSales_auc<-Auction_Dt %>% filter(as.Date(EffectiveDate)>=thirdLastM)
olderSales_auc<-Auction_Dt %>% filter(as.Date(EffectiveDate)<thirdLastM)
############################### plots #############################
for (i in 1:t){
plot_name = paste(plots_schedlist[i,2])
# sales data
auc_data = Auction_modDt %>% filter(Schedule == as.character(plots_schedlist[i,1]))
ret_data = Retail_modDt %>% filter(Schedule == as.character(plots_schedlist[i,1]))
# prior schedules
lstm_scheds = priorScheds %>% filter(Schedule == as.character(plots_schedlist[i,1]))
# inprogress schedules
new_scheds = inprogScheds %>% filter(Schedule == as.character(plots_schedlist[i,1]))
# dots
older_auc<-olderSales_auc %>% filter(Schedule == as.character(plots_schedlist[i,1]))
older_ret<-olderSales_ret %>% filter(Schedule == as.character(plots_schedlist[i,1]))
newer_auc<-recentSales_auc %>% filter(Schedule == as.character(plots_schedlist[i,1]))
newer_ret<-recentSales_ret %>% filter(Schedule == as.character(plots_schedlist[i,1]))
xaxis = c(-.5,11)
yaxis = c(0,2)
yaxis_name='SP /AB Cost'
######## Draw the dots #######
drawolder_Auc<-xyplot(SaleAB ~ Age, older_auc,pch=20,cex=1.5,ylim=yaxis,xlim=xaxis,ylab = yaxis_name,col="deepskyblue1", main=list(label=paste(plot_name,' - ' ,publishDate),font=2,cex=2))
drawolder_Ret<-xyplot(SaleAB ~ Age, older_ret,pch=20,cex=1.5,ylim=yaxis,xlim=xaxis,ylab = yaxis_name,col="lightpink")
drawrecent_Auc<-xyplot(SaleAB ~ Age, newer_auc,pch=20,cex=1.5,ylim=yaxis,xlim=xaxis,ylab = yaxis_name,col="dodgerblue3")
drawrecent_Ret<-xyplot(SaleAB ~ Age, newer_ret,pch=20,cex=1.5,ylim=yaxis,xlim=xaxis,ylab = yaxis_name,col="firebrick2")
######## Draw the lines #######
# prior
drawprior_Auc<-xyplot(priorflv ~ Age, lstm_scheds,ylim=yaxis,xlim=xaxis,type=c('p','l'),lty=3,col='dodgerblue3',ylab = yaxis_name,lwd=3,pch=4,cex=1.5)
drawprior_Ret<-xyplot(priorfmv ~ Age, lstm_scheds,ylim=yaxis,xlim=xaxis,type=c('p','l'),lty=3,col='firebrick2',ylab = yaxis_name,lwd=3,pch=4,cex=1.5)
# US
drawusa_Auc<-xyplot(flv_usa ~ Age, new_scheds,ylim=yaxis,xlim=xaxis,scales = list(y=list(tick.number=10),x=list(tick.number=12))
,type=c("l","g"),col='dodgerblue3',lwd=1.5,lty=1,cex=1,ylab = yaxis_name)
drawusa_Ret<-xyplot(fmv_usa ~ Age, new_scheds,ylim=yaxis,xlim=xaxis,scales = list(y=list(tick.number=10),x=list(tick.number=12))
,type=c("l","g"),col='firebrick2',lwd=1.5,lty=1,cex=1,ylab = yaxis_name)
# CAN
drawcan_Auc<-xyplot(flv_can ~ Age, new_scheds,ylim=yaxis,xlim=xaxis,scales = list(y=list(tick.number=10),x=list(tick.number=12))
,type=c('p','l','g'),col='dodgerblue3',lwd=3,pch=4,cex=1.5, lty=1
,ylab = yaxis_name
,panel = function(x,y,...){
panel.abline(v = 0:14, h = seq(0,2,.5), col="lightgrey")
panel.xyplot(x, y, ...)
})
drawcan_Ret<-xyplot(fmv_can ~ Age, new_scheds,ylim=yaxis,xlim=xaxis,scales = list(y=list(tick.number=10),x=list(tick.number=12))
,type=c('p','l','g'),col='firebrick2',lwd=3,pch=4,cex=1.5,lty=1,ylab = yaxis_name)
draw<- drawolder_Auc + as.layer(drawrecent_Auc) + as.layer(drawolder_Ret) + as.layer(drawrecent_Ret) + as.layer(drawusa_Auc) + as.layer(drawusa_Ret) + as.layer(drawprior_Auc) + as.layer(drawprior_Ret) + as.layer(drawcan_Ret) + as.layer(drawcan_Auc)
mypath<-file.path(file_path,plotFolder,paste(plot_name,".png"))
png(file=mypath,width=1600,height=1200)
print(draw)
dev.off()
}
library(RODBC)
library(RODBCext)
library(lattice)
library(latticeExtra)
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(xlsx)
#library(readxl)
library(stringr)
# country
# country
CountryCode = 'USA'
# db enviroment & connect
DBserver = 'production'
## read input excel file and create a plot for storing the plots
file_path ="H:/Projects/81_WholeSales/doc"
#file_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/doc"
setwd(file_path)
excelfile = '20200806 SchedulesManagement.xlsx'
plotFolder = paste("Plots",Sys.Date())
dir.create(plotFolder)
## set directory of r scripts
scripts_path ="H:/Projects/81_WholeSales/script"
#scripts_path = "C:/Users/vanessa.li/Documents/GitHub/Schedules/script"
setwd(scripts_path)
runa<-parse('ws.input_func.r')
eval(runa)
starttime_dtload<-Sys.time()
channel<-odbcConnect(DBserver)
setwd(scripts_path)
runwholesales<-parse('ws.sqlQueries.r')
eval(runwholesales)
# load each table in sql
wholesales <- sqlQuery(channel,wholesaledata)
schedule.cat <- sqlQuery(channel,sched.cat)
schedule.subcat <- sqlQuery(channel,sched.subcat)
schedule.make <- sqlQuery(channel,sched.make)
inprog.cat<-sqlQuery(channel,cat.inprog)
inprog.subcat<-sqlQuery(channel,subcat.inprog)
inprog.make<-sqlQuery(channel,make.inprog)
AllClass<-sqlQuery(channel,AllClass.sql)
end_time_dtload <- Sys.time()
end_time_dtload - starttime_dtload
# publish date
publishDate <- Sys.Date() - days(day(Sys.Date()))
priorMonth<-as.Date(publishDate- days(day(publishDate)))
## run model script
start_time_r <- Sys.time()
runmodel<-parse('ws.model.r')
eval(runmodel)
setwd(file_path)
#write.xlsx2(as.data.frame(joinMakeOut),file = paste(publishDate,CountryCode," Share.xlsx"), sheetName = 'MakeAdjusters',row.names = F)
end_time_r <- Sys.time()
end_time_r - start_time_r
file_path
## read input excel file and create a plot for storing the plots
file_path ="C:/Users/vanessa.li/Documents/GitHub/Wholesale-values/doc"
## set directory of r scripts
scripts_path ="C:/Users/vanessa.li/Documents/GitHub/Wholesale-values/script"
## run model script
start_time_r <- Sys.time()
runmodel<-parse('ws.model.r')
eval(runmodel)
setwd(file_path)
#write.xlsx2(as.data.frame(joinMakeOut),file = paste(publishDate,CountryCode," Share.xlsx"), sheetName = 'MakeAdjusters',row.names = F)
end_time_r <- Sys.time()
end_time_r - start_time_r
### This process starts from effective date 2019-02-28 and will end in 2020-09-30. ###
EOMList<-seq(as.Date('2019-03-01'),length=20,by='1 month') -1
str <-sort(c(0:9,0:9))
CatDtUse <-data.frame(EOMList,str)
indexUse<- CatDtUse[CatDtUse$EOMList==publishDate,]$str
################### read the tabs from excel ##########################
setwd(file_path)
In<-data.frame(read.xlsx(excelfile,sheetName='In')) %>% filter(Country==CountryCode) %>% select(Schedule,CategoryId,SubcategoryId,MakeId,Country,Level2)
InR<-data.frame(read.xlsx(excelfile,sheetName='InR'))  %>% filter(Country==CountryCode) %>% select(Schedule,CategoryId,SubcategoryId,MakeId,Country,Level2)
combIn<-rbind(In,InR)
Out<-data.frame(read.xlsx(excelfile,sheetName='Out')) %>% filter(Country==CountryCode)
OutR<-data.frame(read.xlsx(excelfile,sheetName='OutR')) %>% filter(Country==CountryCode)
### Application tab
comb_Out<-rbind(Out %>% select(ClassificationId, Schedule,Plot,Level2),OutR %>% select(ClassificationId, Schedule, Plot,Level2))
### load the Sched file
Sched<-data.frame(read.xlsx(excelfile,sheetName='Sched',startRow=6)) %>% filter(Country==CountryCode) %>% select(Schedule,RetailNewYrMin, RetailNewYrMax, AuctionNewYrMin, AuctionNewYrMax)
SchedR<-data.frame(read.xlsx(excelfile,sheetName='SchedR',startRow=6)) %>% filter(Country==CountryCode) %>% select(Schedule,RetailNewYrMin, RetailNewYrMax, AuctionNewYrMin, AuctionNewYrMax,BorrowSchedule,BorrowType)
SchedFullList<-rbind(Sched,SchedR %>% select(-BorrowSchedule,-BorrowType))
SchedFullList <- SchedFullList%>% select(Schedule)
################################ Clean the table and data ##########################################
## split the input file into three levels
Catlevel<-combIn %>% filter(Level2 =='Category') %>% select(Schedule,CategoryId,Country)
Subcatlevel<-combIn %>% filter(Level2 == "SubcatGroup") %>% select(Schedule,CategoryId,SubcategoryId,Country)
Makelevel<-combIn %>% filter(Level2 =='Make') %>% select(Schedule,CategoryId,SubcategoryId,MakeId,Country)
## join the above three levels sub table each level schedules
cat_mapsched <-merge(schedule.cat,Catlevel,by='CategoryId') %>% select(CategoryId,M1AppraisalBookPublishDate,ModelYear,fmv,flv,Schedule,Country)
subcat_mapsched <-merge(schedule.subcat,Subcatlevel,by=c('CategoryId','SubcategoryId'))%>% select(CategoryId,SubcategoryId,M1AppraisalBookPublishDate,ModelYear,fmv,flv,Schedule,Country)
make_mapsched <-merge(schedule.make,Makelevel,by=c('CategoryId','SubcategoryId','MakeId'))%>% select(CategoryId,SubcategoryId,MakeId,M1AppraisalBookPublishDate,ModelYear,fmv,flv,Schedule,Country)
## join the in progress schedules to above three levels sub table each level schedules
cat_mapto_inprog <-merge(inprog.cat,Catlevel,by='CategoryId') %>% select(CategoryId,ModelYear,fmv,flv,Schedule,Country)
subcat_mapto_inprog <-merge(inprog.subcat,Subcatlevel,by=c('CategoryId','SubcategoryId'))%>% select(CategoryId,SubcategoryId,ModelYear,fmv,flv,Schedule,Country)
make_mapto_inprog <-merge(inprog.make,Makelevel,by=c('CategoryId','SubcategoryId','MakeId'))%>% select(CategoryId,SubcategoryId,MakeId,ModelYear,fmv,flv,Schedule,Country)
select.var<-c('CompId',	'CategoryId',	'CategoryName',	'SubcategoryId',	'SubcategoryName',	'MakeId',	'MakeName',	'ModelId',	'ModelName',
'ModelYear',	'SaleDate',	'EffectiveDate',	'SalePrice',	'M1Value',	'SaleType',	'M1AppraisalBookPublishDate',	'SaleAB',
'SPvalue',	'CurrentABCost',	'Age',	'Schedule','fmv','flv')
## validation on mapping
if(
dim(cat_mapsched)[1] == dim(Catlevel)[1]*12*12 &
dim(subcat_mapsched)[1] == dim(Subcatlevel)[1]*12*12 &
dim(make_mapsched)[1] == dim(Makelevel)[1]*12*12){
print("Mapping works good")
} else{print("Check needs on mapping")}
## join the data and combine the three levels into one giant table
CatData <- merge(wholesales,cat_mapsched, by=c("CategoryId","Country","M1AppraisalBookPublishDate","ModelYear")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(all_of(select.var))
SubcatData <- merge(wholesales,subcat_mapsched, by=c('CategoryId',"SubcategoryId","Country","M1AppraisalBookPublishDate","ModelYear")) %>%
mutate(str = str_sub(CompId,-1)) %>%
filter(MakeId !=31 | (MakeId ==31 & str<=indexUse)) %>%
select(all_of(select.var))
MakeData<-merge(wholesales,make_mapsched, by=c('CategoryId',"SubcategoryId","MakeId","Country","M1AppraisalBookPublishDate","ModelYear")) %>%
select(all_of(select.var))
## assign flv, fmv and schedule name to dealer data
Datainput.ws<-rbind(CatData,SubcatData,MakeData) %>%
mutate(CompId = factor(CompId)) %>%
mutate(factor.ind = (SaleAB-flv)/(fmv-flv))%>%
group_by(Schedule) %>%
filter(SPvalue <= mean(SPvalue) + stdInd*sd(SPvalue) & SPvalue>= mean(SPvalue) - stdInd*sd(SPvalue))
## calc new year factor
ws.newy<-Datainput.ws %>%
filter(Age<=ny.max) %>%
group_by(Schedule) %>%
summarise(age = mean(Age),
n=n(),
factor = mean(factor.ind))
ws.newy.full<-merge(SchedFullList,ws.newy,all.x=T,by='Schedule')
nyinherit<-inherit.fact(ws.newy.full) %>% select(-CS_ClassId,-C_ClassId) %>%
rename(factor.ny=factor,
n.ny=n)
## calc old year factor
ws.oldy<-Datainput.ws %>%
filter(Age>=oy.min & Age<=oy.max) %>%
group_by(Schedule) %>%
summarise(age = mean(Age),
n=n(),
factor = mean(factor.ind))
ws.oldy.full<-merge(SchedFullList,ws.oldy,all.x=T,by='Schedule')
oyinherit<-inherit.fact(ws.oldy.full) %>% select(-CS_ClassId,-C_ClassId)%>%
rename(factor.oy=factor,
n.oy=n)
## join the old and new
new.old.join<-merge(nyinherit,oyinherit,by='ClassificationId')
## global values
globalvalue<-data.frame(ClassificationId = GlobalClassId,
factor.ny = globvalue(ws.newy.full),
n.ny = 100,
factor.oy = globvalue(ws.oldy.full),
n.oy=100)
## cap the factor
cap.factor<-rbind(globalvalue,new.old.join) %>%
mutate(ny.cap = pmax(pmin(factor.ny,maxf),minf),
oy.cap = pmax(pmin(factor.oy,maxf),minf))
## import table
importtable<-cap.factor %>% mutate(MarketCode = 'USNA') %>%
rename(WholesalesFactorNY = ny.cap, WholesalesFactorOY = oy.cap) %>%
select(MarketCode,ClassificationId,WholesalesFactorNY,WholesalesFactorOY)
dim(importtable)[1] == dim(comb_Out)[1]
plotscheds<-merge(comb_Out,cap.factor,by='ClassificationId',all.x=T) %>%
filter(Plot == 'Y') %>%
mutate(plotflag.ny = ifelse(n.ny<=thresold_ws | is.na(n.ny), 'inherit','self'),
plotflag.oy = ifelse(n.oy<=thresold_ws | is.na(n.oy), 'inherit','self')) %>%
select(ClassificationId,Schedule,ny.cap,oy.cap,plotflag.ny,plotflag.oy)
dim(importtable)[1]
dim(comb_Out)[1]
write.csv(importtable,"WholesImport.csv")
library(googleCloudStorageR)
install.packages("googleCloudStorageR")
library(googleCloudStorageR)
gcs_global_bucket(projectid)
projectid = 'appraisals-data-dev-c55fa4-wholesale-value-etl'
gcs_global_bucket(projectid)
## custom upload function to ignore quotes and column headers
f <- function(input, output) {
write.table(input, sep = ",", col.names = FALSE, row.names = FALSE,
quote = FALSE, file = output, qmethod = "double")}
## upload files to Google Cloud Storage
gcs_upload(importtable, name = "WholeSaleImport.csv", object_function = f)
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = projectid,
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json")
## upload files to Google Cloud Storage
gcs_upload(importtable, name = "WholeSaleImport.csv", object_function = f)
## upload files to Google Cloud Storage
gcs_upload(importtable, name = "WholeSaleImport.csv", object_function = f)
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = projectid,
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/.last_update_check.json")
## upload files to Google Cloud Storage
gcs_upload(importtable, name = "WholeSaleImport.csv", object_function = f)
## upload an R data.frame directly, with a custom function
upload <- function(input, output) write.csv(input, row.names = FALSE, file = output)
gcs_upload(importtable,
object_function = upload,
type = "csv")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = projectid,
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/.last_update_check.json")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/.last_update_check.json")
GCS_DEFAULT_BUCKET
a<-GCS_DEFAULT_BUCKET
library(googleCloudStorageR)
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/.last_update_check.json")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:\Users\vanessa.li\AppData\Roaming\gcloud\application_default_credentials.json")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users\vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
## upload files to Google Cloud Storage
gcs_upload(importtable, name = "upload/WholeSaleImport.csv", object_function = f)
#Set environment variables
print(Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json"))
## upload an R data.frame directly, with a custom function
f <- function(input, output) write.csv(input, row.names = FALSE, file = output)
gcs_upload(importtable, name = "upload/WholeSaleImport.csv", object_function = f)
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/Documents\GitHub/Wholesale-values/script/application_default_credentials.json")
Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/Documents/GitHub/Wholesale-values/script/application_default_credentials.json")
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
library(googleCloudStorageR)
## GCS_AUTH_FILE set so auto-authentication
gcs_get_bucket("GCS_DEFAULT_BUCKET")
#Set environment variables
print(Sys.setenv("GCS_DEFAULT_BUCKET" = 'appraisals-data-dev-c55fa4-wholesale-value-etl',
"GCS_AUTH_FILE" = "C:/Users/vanessa.li/AppData/Roaming/gcloud/application_default_credentials.json"))
GCS_AUTH_FILE
$GCS_AUTH_FILE
print(GCS_AUTH_FILE)
print($GCS_AUTH_FILE)
print(as.list(.GlobalEnv))
get('GCS_AUTH_FILE', envir=i)
get('GCS_AUTH_FILE')
